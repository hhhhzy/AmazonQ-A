{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N    1574\n",
      "S    1034\n",
      "Y    1020\n",
      "Name: is_answerable_orig, dtype: int64\n",
      "Total 3629\n"
     ]
    }
   ],
   "source": [
    "filename = 'classification_data/final_annotated_data_consistent.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(df.is_answerable_orig.value_counts())\n",
    "print('Total', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df, name='df'):\n",
    "    print(name.upper())\n",
    "    print('Length = %d' % len(df))\n",
    "    print('IsAnswerableOrig Counts')\n",
    "    print(df.is_answerable_orig.value_counts())\n",
    "    print('IsAnswerableNew Counts')\n",
    "    print(df.is_answerable_new.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Length = 3348\n",
      "IsAnswerableOrig Counts\n",
      "N    1436\n",
      "S     958\n",
      "Y     954\n",
      "Name: is_answerable_orig, dtype: int64\n",
      "IsAnswerableNew Counts\n",
      "Series([], Name: is_answerable_new, dtype: int64)\n",
      "\n",
      "TEST\n",
      "Length = 281\n",
      "IsAnswerableOrig Counts\n",
      "N    138\n",
      "S     76\n",
      "Y     66\n",
      "Name: is_answerable_orig, dtype: int64\n",
      "IsAnswerableNew Counts\n",
      "N    134\n",
      "S     77\n",
      "Y     70\n",
      "Name: is_answerable_new, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = df[~df.expert]\n",
    "test_df = df[df.expert]\n",
    "test_df = test_df[test_df.is_answerable_new.notnull()]\n",
    "\n",
    "print_stats(train_df, 'train')\n",
    "print_stats(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3348\n",
      "3348\n",
      "3303\n",
      "\n",
      "\n",
      "281\n",
      "280\n",
      "134\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "# Column Renames\n",
    "cols = ['question', 'review0', 'review1', 'review2', 'review3', 'review4', 'is_answerable']\n",
    "\n",
    "train_df = train_df.rename(columns={'is_answerable_orig': 'is_answerable'})[cols]\n",
    "\n",
    "test_df = test_df.rename(columns={'is_answerable_orig': 'is_answerable', \n",
    "                                  'is_answerable_new': 'is_answerable_human'})[cols + ['is_answerable_human']]\n",
    "\n",
    "\n",
    "def filter_data(df):\n",
    "    print(len(df))\n",
    "    df = df[df.is_answerable.notnull()]\n",
    "    print(len(df))\n",
    "    df = df[df.review0.notnull()]\n",
    "    print(len(df))\n",
    "    return df\n",
    "\n",
    "train_df = filter_data(train_df)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "test_df = filter_data(test_df)\n",
    "test_df_human = test_df[test_df.is_answerable_human.notnull()]\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validate_df = np.split(train_df.sample(frac=1), [int(.8*len(train_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2642, 661, 134)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(validate_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518, 384, 69)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labels(df):\n",
    "    df['label'] = df.is_answerable.apply(lambda x: label_map[x])\n",
    "    return df['label']\n",
    "\n",
    "def get_reviews(row):\n",
    "    all_reviews = ''\n",
    "    for key in ['review0', 'review1', 'review2', 'review3', 'review4']:\n",
    "        if not isinstance(row[key], float):\n",
    "            all_reviews += row[key].strip(' ').strip('-')\n",
    "            all_reviews += ' '\n",
    "    return all_reviews.strip()\n",
    "\n",
    "def add_reviews(df):\n",
    "    df['reviews'] = df.apply(lambda x: get_reviews(x), axis = 1)\n",
    "    return df\n",
    "\n",
    "def remove_non_answerable(df):\n",
    "    return df[df.label != 2]\n",
    "\n",
    "label_map = {'N': 2, 'S': 0, 'Y': 1, 'A': 1}\n",
    "for i, j in zip([1, 2, 3], [1, 0, 2]):\n",
    "    label_map[i] = j\n",
    "    label_map[str(i)] = j\n",
    "\n",
    "train_df, test_df, validate_df = list(map(add_reviews, [train_df, test_df, validate_df]))\n",
    "train_labels, test_labels, validate_labels = list(map(labels, [train_df, test_df, validate_df]))\n",
    "train_df, test_df, validate_df = list(map(remove_non_answerable, [train_df, test_df, validate_df]))\n",
    "\n",
    "len(train_df), len(validate_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pd.read_csv('classification_data/train-qar_sample_100000.csv')\\ndf = add_reviews(df)\\nprint(len(df))\\n\\ntfidf_vectorizer = TfidfVectorizer(stop_words='english')\\ntfidf_vectorizer.fit(list(df.question.values) + list(df.reviews.values))\\n\\nwith open('classification_data/q_classification_vectorizer.pkl', 'wb') as fp:\\n    pickle.dump(tfidf_vectorizer, fp)\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df = pd.read_csv('classification_data/train-qar_sample_100000.csv')\n",
    "df = add_reviews(df)\n",
    "print(len(df))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer.fit(list(df.question.values) + list(df.reviews.values))\n",
    "\n",
    "with open('classification_data/q_classification_vectorizer.pkl', 'wb') as fp:\n",
    "    pickle.dump(tfidf_vectorizer, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classification_data/q_classification_vectorizer.pkl', 'rb') as fp:\n",
    "    tfidf_vectorizer = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158752"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2v Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# with open(\"classification_data/glove.6B.300d.txt\", \"rb\") as lines:\n",
    "#     w2v = {str(line.split()[0].decode('UTF-8')): np.array(list(map(float, line.split()[1:])))\n",
    "#            for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classification_data/q_classification_w2v_vectorizer.pkl', 'rb') as fp:\n",
    "    w2v_vectorizer = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_vectorizer = MeanEmbeddingVectorizer(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('classification_data/q_classification_w2v_vectorizer.pkl', 'wb') as fp:\n",
    "#     pickle.dump(w2v_vectorizer, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_raw, test_df_raw, validate_df_raw = list(map(lambda x: x.copy(), [train_df, test_df, validate_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    punctuations = string.punctuation.replace(\"\\'\", '')\n",
    "\n",
    "    for ch in punctuations:\n",
    "        text = text.replace(ch, \" \" + ch + \" \")\n",
    "\n",
    "    tokens = text.split()\n",
    "    for i, token in enumerate(tokens):\n",
    "        if not token.isupper():\n",
    "            tokens[i] = token.lower()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = vectorizer.transform([\\'It is a total idiot\\'])\\ny = vectorizer.transform([\\'It is not a total idiocy\\'])\\n\\nprint(type(x), \\'|\\n\\', x.shape, \\'|\\n\\', x, \\'|\\n\\', len(x.toarray()[0]))\\nprint(\"-\"*50)\\nprint(type(y), \\'|\\n\\', y.shape, \\'|\\n\\', y, \\'|\\n\\', len(y.toarray()[0]))\\nprint(\"-\"*50)\\nprint(x.toarray().dot(y.toarray().transpose())[0][0])\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = vectorizer.transform(['It is a total idiot'])\n",
    "y = vectorizer.transform(['It is not a total idiocy'])\n",
    "\n",
    "print(type(x), '|\\n', x.shape, '|\\n', x, '|\\n', len(x.toarray()[0]))\n",
    "print(\"-\"*50)\n",
    "print(type(y), '|\\n', y.shape, '|\\n', y, '|\\n', len(y.toarray()[0]))\n",
    "print(\"-\"*50)\n",
    "print(x.toarray().dot(y.toarray().transpose())[0][0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_intersection(q, r):\n",
    "    return len(set(q).intersection(set(r)))\n",
    "\n",
    "def w2v_sim(q, r):\n",
    "    # dot product of q and r as w2v vectors\n",
    "    q_vec = w2v_vectorizer.transform([q])\n",
    "    r_vec = w2v_vectorizer.transform([r])\n",
    "    return q_vec.dot(r_vec.transpose())[0][0]\n",
    "\n",
    "def tf_idf_sim(q, r):\n",
    "    # dot product of q and r as tfidf vectors\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    r_vec = tfidf_vectorizer.transform([r])\n",
    "    return q_vec.dot(r_vec.transpose()).toarray()[0][0]\n",
    "\n",
    "def tf_idf_sim_sentence(q, rs):\n",
    "    # max of dot products of q and each sentence in r as tfidf vectors\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    if len(rs) == 0:\n",
    "        return 0\n",
    "    return max([q_vec.dot(tfidf_vectorizer.transform([r]).transpose()).toarray()[0][0] for r in rs])\n",
    "\n",
    "def w2v_sim_sentence(q, rs):\n",
    "    # max of dot products of q and each sentence in r as tfidf vectors\n",
    "    q_vec = w2v_vectorizer.transform([q])\n",
    "    if len(rs) == 0:\n",
    "        return 0\n",
    "    return max([q_vec.dot(w2v_vectorizer.transform([r]).transpose())[0][0] for r in rs])\n",
    "\n",
    "def tf_idf_sim_sentence_mean(q, rs):\n",
    "    # max of dot products of q and each sentence in r as tfidf vectors\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    if len(rs) == 0:\n",
    "        return 0\n",
    "    return np.mean([q_vec.dot(tfidf_vectorizer.transform([r]).transpose()).toarray()[0][0] for r in rs])\n",
    "\n",
    "def w2v_sim_sentence_mean(q, rs):\n",
    "    # max of dot products of q and each sentence in r as tfidf vectors\n",
    "    q_vec = w2v_vectorizer.transform([q])\n",
    "    if len(rs) == 0:\n",
    "        return 0\n",
    "    return np.mean([q_vec.dot(w2v_vectorizer.transform([r]).transpose())[0][0] for r in rs])\n",
    "\n",
    "def add_features(df):\n",
    "    df['q_tokens'] = df.question.apply(lambda x: tokenize(x))\n",
    "    df['r_tokens'] = df.reviews.apply(lambda x: tokenize(x))\n",
    "    df['r_sents'] = df.reviews.apply(lambda x: sent_tokenize(x))\n",
    "    df['n_q'] = df.q_tokens.apply(lambda x: len(x))\n",
    "    df['n_r'] = df.r_tokens.apply(lambda x: len(x))\n",
    "    df['n_intersection'] = df.apply(lambda x: len(set(x.q_tokens).intersection(set(x.r_tokens))), axis=1)\n",
    "    df['intr_frac'] = df.n_intersection / df.n_q\n",
    "    df['tfidf'] = df.apply(lambda x: tf_idf_sim(x.question, x.reviews), axis=1)\n",
    "    df['w2v'] = df.apply(lambda x: w2v_sim(x.question, x.reviews), axis=1)\n",
    "    df['w2v_sent'] = df.apply(lambda x: w2v_sim_sentence(x.question, x.r_sents), axis=1)\n",
    "    df['tfidf_sent'] = df.apply(lambda x: tf_idf_sim_sentence(x.question, x.r_sents), axis=1)\n",
    "    df['w2v_sent_mean'] = df.apply(lambda x: w2v_sim_sentence_mean(x.question, x.r_sents), axis=1)\n",
    "    df['tfidf_sent_mean'] = df.apply(lambda x: tf_idf_sim_sentence_mean(x.question, x.r_sents), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, validate_df = list(map(add_features, [train_df_raw, test_df_raw, validate_df_raw]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_test, prev_val = test_df, validate_df\n",
    "# test_df = pd.concat([test_df, validate_df], axis=0, sort=False)\n",
    "# validate_df = test_df\n",
    "validate_df = prev_val\n",
    "test_df = prev_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['n_q', 'n_r', 'n_intersection', 'intr_frac']\n",
    "Y_cols = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df\n",
    "\n",
    "q = df.question.iloc[1]\n",
    "r = df.reviews.iloc[1]\n",
    "q_tokens = df.q_tokens.iloc[1]\n",
    "r_tokens = df.r_tokens.iloc[1]\n",
    "\n",
    "# q, r, set(q_tokens).intersection(set(r_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_q</th>\n",
       "      <th>n_r</th>\n",
       "      <th>n_intersection</th>\n",
       "      <th>intr_frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.42556</td>\n",
       "      <td>370.206851</td>\n",
       "      <td>9.770751</td>\n",
       "      <td>0.563011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.87220</td>\n",
       "      <td>387.038208</td>\n",
       "      <td>9.629776</td>\n",
       "      <td>0.607933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            n_q         n_r  n_intersection  intr_frac\n",
       "label                                                 \n",
       "0      18.42556  370.206851        9.770751   0.563011\n",
       "1      16.87220  387.038208        9.629776   0.607933"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[Y_cols] + X_cols].groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/rchanda/Acads/Fall-2018/Capstone/eqa_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_colss = [\n",
    "    #X_cols + ['tfidf', 'tfidf_sent'],\n",
    "    #X_cols + ['w2v', 'w2v_sent'],\n",
    "    #X_cols + ['w2v_sent_mean', 'tfidf_sent_mean'],\n",
    "    X_cols + ['w2v_sent', 'tfidf_sent', 'w2v_sent_mean', 'tfidf_sent_mean'],\n",
    "    X_cols + ['w2v_sent', 'tfidf_sent'],\n",
    "    \n",
    "    X_cols + ['tfidf_sent'],\n",
    "    X_cols + ['w2v_sent'],\n",
    "    X_cols + ['tfidf', 'tfidf_sent', 'w2v', 'w2v_sent'],\n",
    "]\n",
    "\n",
    "n_col_set = len(X_colss)\n",
    "modelss = []\n",
    "\n",
    "for j in range(n_col_set):\n",
    "    models = []\n",
    "    models.append(LogisticRegression(C=1))\n",
    "    models.append(LogisticRegression(C=100))\n",
    "    models.append(DecisionTreeClassifier(max_depth=4))\n",
    "    models.append(RandomForestClassifier(n_estimators=3, max_depth=4))\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        models[i].fit(train_df[X_colss[j]].values, train_df[Y_cols].values)\n",
    "    modelss.append(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0    197\n",
      "1    187\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       192\n",
      "           1       0.57      0.55      0.56       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.57       384\n",
      "weighted avg       0.57      0.57      0.57       384\n",
      "\n",
      "0 1\n",
      "0    196\n",
      "1    188\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55       192\n",
      "           1       0.55      0.54      0.54       192\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       384\n",
      "   macro avg       0.55      0.55      0.55       384\n",
      "weighted avg       0.55      0.55      0.55       384\n",
      "\n",
      "0 2\n",
      "1    216\n",
      "0    168\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.49      0.53       192\n",
      "           1       0.55      0.62      0.58       192\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       384\n",
      "   macro avg       0.56      0.56      0.56       384\n",
      "weighted avg       0.56      0.56      0.56       384\n",
      "\n",
      "0 3\n",
      "1    193\n",
      "0    191\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53       192\n",
      "           1       0.53      0.54      0.54       192\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       384\n",
      "   macro avg       0.53      0.53      0.53       384\n",
      "weighted avg       0.53      0.53      0.53       384\n",
      "\n",
      "1 0\n",
      "0    199\n",
      "1    185\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       192\n",
      "           1       0.57      0.55      0.56       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.56       384\n",
      "weighted avg       0.57      0.57      0.56       384\n",
      "\n",
      "1 1\n",
      "0    197\n",
      "1    187\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       192\n",
      "           1       0.57      0.55      0.56       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.57       384\n",
      "weighted avg       0.57      0.57      0.57       384\n",
      "\n",
      "1 2\n",
      "1    221\n",
      "0    163\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.46      0.50       192\n",
      "           1       0.53      0.61      0.57       192\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       384\n",
      "   macro avg       0.54      0.54      0.54       384\n",
      "weighted avg       0.54      0.54      0.54       384\n",
      "\n",
      "1 3\n",
      "0    194\n",
      "1    190\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       192\n",
      "           1       0.56      0.55      0.55       192\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       384\n",
      "   macro avg       0.56      0.56      0.56       384\n",
      "weighted avg       0.56      0.56      0.56       384\n",
      "\n",
      "2 0\n",
      "0    200\n",
      "1    184\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.58       192\n",
      "           1       0.57      0.55      0.56       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.57       384\n",
      "weighted avg       0.57      0.57      0.57       384\n",
      "\n",
      "2 1\n",
      "0    204\n",
      "1    180\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.58       192\n",
      "           1       0.57      0.53      0.55       192\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       384\n",
      "   macro avg       0.56      0.56      0.56       384\n",
      "weighted avg       0.56      0.56      0.56       384\n",
      "\n",
      "2 2\n",
      "1    197\n",
      "0    187\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       192\n",
      "           1       0.57      0.59      0.58       192\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       384\n",
      "   macro avg       0.58      0.58      0.58       384\n",
      "weighted avg       0.58      0.58      0.58       384\n",
      "\n",
      "2 3\n",
      "0    233\n",
      "1    151\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60       192\n",
      "           1       0.57      0.45      0.50       192\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       384\n",
      "   macro avg       0.56      0.55      0.55       384\n",
      "weighted avg       0.56      0.55      0.55       384\n",
      "\n",
      "3 0\n",
      "1    197\n",
      "0    187\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.55      0.56       192\n",
      "           1       0.56      0.58      0.57       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.57       384\n",
      "weighted avg       0.57      0.57      0.57       384\n",
      "\n",
      "3 1\n",
      "1    194\n",
      "0    190\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       192\n",
      "           1       0.56      0.57      0.56       192\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       384\n",
      "   macro avg       0.56      0.56      0.56       384\n",
      "weighted avg       0.56      0.56      0.56       384\n",
      "\n",
      "3 2\n",
      "1    240\n",
      "0    144\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48       192\n",
      "           1       0.54      0.67      0.60       192\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       384\n",
      "   macro avg       0.55      0.55      0.54       384\n",
      "weighted avg       0.55      0.55      0.54       384\n",
      "\n",
      "3 3\n",
      "0    218\n",
      "1    166\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.54       192\n",
      "           1       0.51      0.44      0.47       192\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       384\n",
      "   macro avg       0.51      0.51      0.51       384\n",
      "weighted avg       0.51      0.51      0.51       384\n",
      "\n",
      "4 0\n",
      "0    201\n",
      "1    183\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.59      0.58       192\n",
      "           1       0.57      0.55      0.56       192\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       384\n",
      "   macro avg       0.57      0.57      0.57       384\n",
      "weighted avg       0.57      0.57      0.57       384\n",
      "\n",
      "4 1\n",
      "0    198\n",
      "1    186\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55       192\n",
      "           1       0.55      0.53      0.54       192\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       384\n",
      "   macro avg       0.55      0.55      0.55       384\n",
      "weighted avg       0.55      0.55      0.55       384\n",
      "\n",
      "4 2\n",
      "1    207\n",
      "0    177\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52       192\n",
      "           1       0.54      0.58      0.56       192\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       384\n",
      "   macro avg       0.54      0.54      0.54       384\n",
      "weighted avg       0.54      0.54      0.54       384\n",
      "\n",
      "4 3\n",
      "0    207\n",
      "1    177\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.56      0.54       192\n",
      "           1       0.53      0.48      0.50       192\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       384\n",
      "   macro avg       0.52      0.52      0.52       384\n",
      "weighted avg       0.52      0.52      0.52       384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for j, models in enumerate(modelss):\n",
    "    for i, model in enumerate(models):\n",
    "        print(j, i)\n",
    "        predictions = model.predict(validate_df[X_colss[j]].values)\n",
    "        print(pd.Series(predictions).value_counts())\n",
    "        print(classification_report(validate_df[Y_cols].values, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.49869452 0.4973822  0.49606299 0.49736842 0.49604222\n",
      " 0.4973545  0.49602122 0.49468085 0.496      0.4973262  0.49597855\n",
      " 0.49731183 0.49595687 0.4972973  0.49593496 0.49456522 0.49591281\n",
      " 0.49726776 0.49863014 0.5        0.50137741 0.50276243 0.50415512\n",
      " 0.50555556 0.50696379 0.50558659 0.50420168 0.50561798 0.50704225\n",
      " 0.50847458 0.50991501 0.51136364 0.50997151 0.50857143 0.50716332\n",
      " 0.50862069 0.51008646 0.51156069 0.51304348 0.51162791 0.51020408\n",
      " 0.51169591 0.51026393 0.51176471 0.51032448 0.51183432 0.51335312\n",
      " 0.51190476 0.51044776 0.50898204 0.51051051 0.50903614 0.50755287\n",
      " 0.50909091 0.5106383  0.50914634 0.50764526 0.50613497 0.50769231\n",
      " 0.50925926 0.50773994 0.50621118 0.5046729  0.50625    0.50783699\n",
      " 0.50943396 0.50788644 0.50949367 0.50793651 0.50636943 0.50798722\n",
      " 0.50961538 0.50803859 0.50967742 0.51132686 0.50974026 0.51140065\n",
      " 0.5130719  0.5147541  0.51315789 0.51485149 0.51655629 0.51827243\n",
      " 0.52       0.52173913 0.52348993 0.52188552 0.52364865 0.5220339\n",
      " 0.52040816 0.5221843  0.5239726  0.5257732  0.52758621 0.52595156\n",
      " 0.52777778 0.52961672 0.52797203 0.52982456 0.52816901 0.52650177\n",
      " 0.5248227  0.52669039 0.525      0.52329749 0.52158273 0.5234657\n",
      " 0.52173913 0.52363636 0.52554745 0.52747253 0.52941176 0.52767528\n",
      " 0.52592593 0.52788104 0.52985075 0.53183521 0.53007519 0.53207547\n",
      " 0.53409091 0.53231939 0.53053435 0.52873563 0.52692308 0.52895753\n",
      " 0.53100775 0.53307393 0.53125    0.53333333 0.53149606 0.53359684\n",
      " 0.53571429 0.53784861 0.54       0.54216867 0.54435484 0.5465587\n",
      " 0.54878049 0.55102041 0.55327869 0.55144033 0.54958678 0.54771784\n",
      " 0.54583333 0.54393305 0.54201681 0.54008439 0.53813559 0.54042553\n",
      " 0.53846154 0.54077253 0.54310345 0.54545455 0.54347826 0.54148472\n",
      " 0.54385965 0.54625551 0.54424779 0.54222222 0.54464286 0.5426009\n",
      " 0.54054054 0.54298643 0.54545455 0.54794521 0.55045872 0.5483871\n",
      " 0.55092593 0.55348837 0.55140187 0.55399061 0.55188679 0.55450237\n",
      " 0.55238095 0.55023923 0.54807692 0.54589372 0.54854369 0.55121951\n",
      " 0.54901961 0.55172414 0.55445545 0.55721393 0.56       0.55778894\n",
      " 0.55555556 0.55837563 0.55612245 0.55384615 0.55670103 0.55440415\n",
      " 0.55208333 0.55497382 0.55789474 0.56084656 0.56382979 0.56684492\n",
      " 0.56451613 0.56756757 0.57065217 0.57377049 0.57692308 0.57458564\n",
      " 0.57222222 0.57541899 0.57303371 0.57062147 0.57386364 0.57714286\n",
      " 0.57471264 0.57803468 0.5755814  0.57894737 0.57647059 0.5739645\n",
      " 0.57738095 0.58083832 0.58433735 0.58181818 0.57926829 0.57668712\n",
      " 0.57407407 0.57763975 0.58125    0.57861635 0.57594937 0.57961783\n",
      " 0.58333333 0.58064516 0.57792208 0.58169935 0.57894737 0.57615894\n",
      " 0.57333333 0.57718121 0.57432432 0.57823129 0.57534247 0.57931034\n",
      " 0.57638889 0.58041958 0.58450704 0.58865248 0.58571429 0.58273381\n",
      " 0.57971014 0.58394161 0.58088235 0.58518519 0.58955224 0.58646617\n",
      " 0.58333333 0.58778626 0.59230769 0.58914729 0.59375    0.59055118\n",
      " 0.58730159 0.584      0.58064516 0.57723577 0.57377049 0.57024793\n",
      " 0.575      0.57142857 0.56779661 0.56410256 0.56896552 0.57391304\n",
      " 0.57894737 0.5840708  0.58035714 0.57657658 0.57272727 0.57798165\n",
      " 0.57407407 0.57943925 0.58490566 0.58095238 0.57692308 0.58252427\n",
      " 0.58823529 0.58415842 0.58       0.57575758 0.58163265 0.57731959\n",
      " 0.57291667 0.57894737 0.57446809 0.58064516 0.58695652 0.59340659\n",
      " 0.6        0.60674157 0.61363636 0.6091954  0.60465116 0.61176471\n",
      " 0.61904762 0.61445783 0.62195122 0.61728395 0.6125     0.60759494\n",
      " 0.6025641  0.61038961 0.61842105 0.61333333 0.60810811 0.60273973\n",
      " 0.59722222 0.5915493  0.58571429 0.5942029  0.60294118 0.6119403\n",
      " 0.60606061 0.6        0.609375   0.61904762 0.61290323 0.62295082\n",
      " 0.61666667 0.62711864 0.62068966 0.61403509 0.625      0.61818182\n",
      " 0.62962963 0.62264151 0.63461538 0.64705882 0.64       0.65306122\n",
      " 0.64583333 0.63829787 0.65217391 0.64444444 0.65909091 0.6744186\n",
      " 0.69047619 0.70731707 0.725      0.74358974 0.76315789 0.75675676\n",
      " 0.75       0.77142857 0.76470588 0.78787879 0.78125    0.77419355\n",
      " 0.76666667 0.75862069 0.78571429 0.81481481 0.80769231 0.8\n",
      " 0.79166667 0.82608696 0.86363636 0.9047619  0.9        0.89473684\n",
      " 0.88888889 0.88235294 0.875      0.86666667 0.85714286 0.84615385\n",
      " 0.83333333 0.81818182 0.8        0.88888889 0.875      0.85714286\n",
      " 0.83333333 0.8        0.75       1.         1.         1.\n",
      " 1.        ] [1.         0.99479167 0.98958333 0.984375   0.984375   0.97916667\n",
      " 0.97916667 0.97395833 0.96875    0.96875    0.96875    0.96354167\n",
      " 0.96354167 0.95833333 0.95833333 0.953125   0.94791667 0.94791667\n",
      " 0.94791667 0.94791667 0.94791667 0.94791667 0.94791667 0.94791667\n",
      " 0.94791667 0.94791667 0.94270833 0.9375     0.9375     0.9375\n",
      " 0.9375     0.9375     0.9375     0.93229167 0.92708333 0.921875\n",
      " 0.921875   0.921875   0.921875   0.921875   0.91666667 0.91145833\n",
      " 0.91145833 0.90625    0.90625    0.90104167 0.90104167 0.90104167\n",
      " 0.89583333 0.890625   0.88541667 0.88541667 0.88020833 0.875\n",
      " 0.875      0.875      0.86979167 0.86458333 0.859375   0.859375\n",
      " 0.859375   0.85416667 0.84895833 0.84375    0.84375    0.84375\n",
      " 0.84375    0.83854167 0.83854167 0.83333333 0.828125   0.828125\n",
      " 0.828125   0.82291667 0.82291667 0.82291667 0.81770833 0.81770833\n",
      " 0.81770833 0.81770833 0.8125     0.8125     0.8125     0.8125\n",
      " 0.8125     0.8125     0.8125     0.80729167 0.80729167 0.80208333\n",
      " 0.796875   0.796875   0.796875   0.796875   0.796875   0.79166667\n",
      " 0.79166667 0.79166667 0.78645833 0.78645833 0.78125    0.77604167\n",
      " 0.77083333 0.77083333 0.765625   0.76041667 0.75520833 0.75520833\n",
      " 0.75       0.75       0.75       0.75       0.75       0.74479167\n",
      " 0.73958333 0.73958333 0.73958333 0.73958333 0.734375   0.734375\n",
      " 0.734375   0.72916667 0.72395833 0.71875    0.71354167 0.71354167\n",
      " 0.71354167 0.71354167 0.70833333 0.70833333 0.703125   0.703125\n",
      " 0.703125   0.703125   0.703125   0.703125   0.703125   0.703125\n",
      " 0.703125   0.703125   0.703125   0.69791667 0.69270833 0.6875\n",
      " 0.68229167 0.67708333 0.671875   0.66666667 0.66145833 0.66145833\n",
      " 0.65625    0.65625    0.65625    0.65625    0.65104167 0.64583333\n",
      " 0.64583333 0.64583333 0.640625   0.63541667 0.63541667 0.63020833\n",
      " 0.625      0.625      0.625      0.625      0.625      0.61979167\n",
      " 0.61979167 0.61979167 0.61458333 0.61458333 0.609375   0.609375\n",
      " 0.60416667 0.59895833 0.59375    0.58854167 0.58854167 0.58854167\n",
      " 0.58333333 0.58333333 0.58333333 0.58333333 0.58333333 0.578125\n",
      " 0.57291667 0.57291667 0.56770833 0.5625     0.5625     0.55729167\n",
      " 0.55208333 0.55208333 0.55208333 0.55208333 0.55208333 0.55208333\n",
      " 0.546875   0.546875   0.546875   0.546875   0.546875   0.54166667\n",
      " 0.53645833 0.53645833 0.53125    0.52604167 0.52604167 0.52604167\n",
      " 0.52083333 0.52083333 0.515625   0.515625   0.51041667 0.50520833\n",
      " 0.50520833 0.50520833 0.50520833 0.5        0.49479167 0.48958333\n",
      " 0.484375   0.484375   0.484375   0.47916667 0.47395833 0.47395833\n",
      " 0.47395833 0.46875    0.46354167 0.46354167 0.45833333 0.453125\n",
      " 0.44791667 0.44791667 0.44270833 0.44270833 0.4375     0.4375\n",
      " 0.43229167 0.43229167 0.43229167 0.43229167 0.42708333 0.421875\n",
      " 0.41666667 0.41666667 0.41145833 0.41145833 0.41145833 0.40625\n",
      " 0.40104167 0.40104167 0.40104167 0.39583333 0.39583333 0.390625\n",
      " 0.38541667 0.38020833 0.375      0.36979167 0.36458333 0.359375\n",
      " 0.359375   0.35416667 0.34895833 0.34375    0.34375    0.34375\n",
      " 0.34375    0.34375    0.33854167 0.33333333 0.328125   0.328125\n",
      " 0.32291667 0.32291667 0.32291667 0.31770833 0.3125     0.3125\n",
      " 0.3125     0.30729167 0.30208333 0.296875   0.296875   0.29166667\n",
      " 0.28645833 0.28645833 0.28125    0.28125    0.28125    0.28125\n",
      " 0.28125    0.28125    0.28125    0.27604167 0.27083333 0.27083333\n",
      " 0.27083333 0.265625   0.265625   0.26041667 0.25520833 0.25\n",
      " 0.24479167 0.24479167 0.24479167 0.23958333 0.234375   0.22916667\n",
      " 0.22395833 0.21875    0.21354167 0.21354167 0.21354167 0.21354167\n",
      " 0.20833333 0.203125   0.203125   0.203125   0.19791667 0.19791667\n",
      " 0.19270833 0.19270833 0.1875     0.18229167 0.18229167 0.17708333\n",
      " 0.17708333 0.171875   0.171875   0.171875   0.16666667 0.16666667\n",
      " 0.16145833 0.15625    0.15625    0.15104167 0.15104167 0.15104167\n",
      " 0.15104167 0.15104167 0.15104167 0.15104167 0.15104167 0.14583333\n",
      " 0.140625   0.140625   0.13541667 0.13541667 0.13020833 0.125\n",
      " 0.11979167 0.11458333 0.11458333 0.11458333 0.109375   0.10416667\n",
      " 0.09895833 0.09895833 0.09895833 0.09895833 0.09375    0.08854167\n",
      " 0.08333333 0.078125   0.07291667 0.06770833 0.0625     0.05729167\n",
      " 0.05208333 0.046875   0.04166667 0.04166667 0.03645833 0.03125\n",
      " 0.02604167 0.02083333 0.015625   0.015625   0.01041667 0.00520833\n",
      " 0.        ] [0.26988119 0.31672469 0.31796538 0.31961591 0.33397852 0.33779304\n",
      " 0.34121585 0.3432572  0.34589084 0.3464493  0.34818984 0.35581919\n",
      " 0.35832871 0.36125574 0.36132117 0.3663794  0.36958589 0.37037846\n",
      " 0.37648636 0.37684336 0.37837572 0.37878924 0.38266188 0.38318934\n",
      " 0.38770342 0.38819972 0.38937323 0.39029502 0.39102552 0.39644767\n",
      " 0.39982334 0.40056875 0.40172699 0.40218321 0.40222735 0.40512892\n",
      " 0.40550096 0.40552096 0.4065727  0.40713739 0.407226   0.40758956\n",
      " 0.40831586 0.41061159 0.41153854 0.41156802 0.41229887 0.4141825\n",
      " 0.41596771 0.41596859 0.41597028 0.41755878 0.41758573 0.41776865\n",
      " 0.41836957 0.41956602 0.41978982 0.42138448 0.42143873 0.42198725\n",
      " 0.42201902 0.4226622  0.42281332 0.4237312  0.42389892 0.42615655\n",
      " 0.42643963 0.42795295 0.4300333  0.43101686 0.43203667 0.43232591\n",
      " 0.43252742 0.43263428 0.43375887 0.43412192 0.43421776 0.4349185\n",
      " 0.43618428 0.43623815 0.43639917 0.43727611 0.4379204  0.43894056\n",
      " 0.43940301 0.43989134 0.44018894 0.44038964 0.44048715 0.44139626\n",
      " 0.44176765 0.44234448 0.44283266 0.44430774 0.44626606 0.44637372\n",
      " 0.44741336 0.44744639 0.44756979 0.44828767 0.44904646 0.44939529\n",
      " 0.44966196 0.44985137 0.45025229 0.45223415 0.45228246 0.45231327\n",
      " 0.45372369 0.45500069 0.45583347 0.45599048 0.45651878 0.45766506\n",
      " 0.45897177 0.45900148 0.45913387 0.45947159 0.45991607 0.46009375\n",
      " 0.46101656 0.46142756 0.46176449 0.46184317 0.46223161 0.46349753\n",
      " 0.46351588 0.46440348 0.46453917 0.46474965 0.46622319 0.46625233\n",
      " 0.46644069 0.46723277 0.46747624 0.46953752 0.47001162 0.47021068\n",
      " 0.47080575 0.47116044 0.47164906 0.4724287  0.47327523 0.47394629\n",
      " 0.47468436 0.47506705 0.47556201 0.47560758 0.47580313 0.47644813\n",
      " 0.47671173 0.47700032 0.47764087 0.47794965 0.47840288 0.47845918\n",
      " 0.47855095 0.47897545 0.47949343 0.48075934 0.48300842 0.48327915\n",
      " 0.48353029 0.48423192 0.48447947 0.48479716 0.4858614  0.48637224\n",
      " 0.48685919 0.48689458 0.48743168 0.48771501 0.4877222  0.48839975\n",
      " 0.48852182 0.48967571 0.48974606 0.49073314 0.49145666 0.49188371\n",
      " 0.49202298 0.49204503 0.49207593 0.49214375 0.49262791 0.49268305\n",
      " 0.49363456 0.49633947 0.49693294 0.49737243 0.49763262 0.49793818\n",
      " 0.49818429 0.49870786 0.49883906 0.49920954 0.4995972  0.49959778\n",
      " 0.49972274 0.49978834 0.49994146 0.50057354 0.50135287 0.50197348\n",
      " 0.50211208 0.50225321 0.50241306 0.50309083 0.50338205 0.50342508\n",
      " 0.50356603 0.50374277 0.50493373 0.50575142 0.50661071 0.50742129\n",
      " 0.50830737 0.50905127 0.51000076 0.51005962 0.51094024 0.51154415\n",
      " 0.51188327 0.5120605  0.51240587 0.51249285 0.51263208 0.51294702\n",
      " 0.51302325 0.51329797 0.51412322 0.5145162  0.51470183 0.51495096\n",
      " 0.51535393 0.51557261 0.51620568 0.51705942 0.51733512 0.51933075\n",
      " 0.5195419  0.51965664 0.52065368 0.52097831 0.52108299 0.52125343\n",
      " 0.52151911 0.52182013 0.52252642 0.52300411 0.52316016 0.52369532\n",
      " 0.52438553 0.52456649 0.52479943 0.52506641 0.52613711 0.52627433\n",
      " 0.52842843 0.52951255 0.52999172 0.53100944 0.53336967 0.53375168\n",
      " 0.53401205 0.53414447 0.53543707 0.53601713 0.53605591 0.53620557\n",
      " 0.53657827 0.53697342 0.53701839 0.5373041  0.53792952 0.53921338\n",
      " 0.53973498 0.53982867 0.54010755 0.54058836 0.54069355 0.54075696\n",
      " 0.54203082 0.54368613 0.54370801 0.54427228 0.54452341 0.54524691\n",
      " 0.54567526 0.54597207 0.54699567 0.5474737  0.54762772 0.54771948\n",
      " 0.54819572 0.54862378 0.55037931 0.55070941 0.55073524 0.55102269\n",
      " 0.55189346 0.55201621 0.55312409 0.55341876 0.5537335  0.55385818\n",
      " 0.55457377 0.55559199 0.55566202 0.55842657 0.55892947 0.5592745\n",
      " 0.56090138 0.56124986 0.56169624 0.56320069 0.56503809 0.56575583\n",
      " 0.56642487 0.5674503  0.56903008 0.56933937 0.56969329 0.57219182\n",
      " 0.57247904 0.57339242 0.5747082  0.57476158 0.57715339 0.5780516\n",
      " 0.57837368 0.57883387 0.57973698 0.58073421 0.58173088 0.58189303\n",
      " 0.58277875 0.58402879 0.5844703  0.58605852 0.58632078 0.58877461\n",
      " 0.59039426 0.59064768 0.59079044 0.59625725 0.59650651 0.59842427\n",
      " 0.59874276 0.59931322 0.5994516  0.60108809 0.6027026  0.60344935\n",
      " 0.60572315 0.60717201 0.60737555 0.60903196 0.60991427 0.61074052\n",
      " 0.61173243 0.61253883 0.61291478 0.61317025 0.61321479 0.61479427\n",
      " 0.61508351 0.61536327 0.6156032  0.62061566 0.62064206 0.62225482\n",
      " 0.62246439 0.62460529 0.62698959 0.62963712 0.63290613 0.63376214\n",
      " 0.64578844 0.64701199 0.6479509  0.64966075 0.65941358 0.66478525]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def plot_curves(model):\n",
    "    probs = model.predict_proba(validate_df[X_colss[4]].values)[:,1]\n",
    "    ytrue = validate_df[Y_cols].values\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(ytrue, probs, pos_label=1)\n",
    "    score = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % score)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(ytrue, probs)\n",
    "    print(precision, recall, thresholds)\n",
    "    plt.figure()\n",
    "    plt.plot(precision, recall, color='darkorange')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.ylabel('Recall')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    thresholds = [0.25, 0.5, 0.75]\n",
    "    for th in thresholds:\n",
    "        #print(probs)\n",
    "        predictions = [1 if prob > th else 0 for prob in probs]\n",
    "        #predictions = model.predict(validate_df[X_cols].values)\n",
    "        print(pd.Series(predictions).value_counts())\n",
    "        print(classification_report(ytrue, predictions))\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "plot_curves(modelss[4][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "False    59\n",
      "True     10\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.90      0.46        20\n",
      "           1       0.80      0.16      0.27        49\n",
      "\n",
      "   micro avg       0.38      0.38      0.38        69\n",
      "   macro avg       0.55      0.53      0.36        69\n",
      "weighted avg       0.66      0.38      0.32        69\n",
      "\n",
      "0 1\n",
      "False    56\n",
      "True     13\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.85      0.45        20\n",
      "           1       0.77      0.20      0.32        49\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        69\n",
      "   macro avg       0.54      0.53      0.38        69\n",
      "weighted avg       0.63      0.39      0.36        69\n",
      "\n",
      "0 2\n",
      "False    59\n",
      "True     10\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.75      0.38        20\n",
      "           1       0.50      0.10      0.17        49\n",
      "\n",
      "   micro avg       0.29      0.29      0.29        69\n",
      "   macro avg       0.38      0.43      0.27        69\n",
      "weighted avg       0.43      0.29      0.23        69\n",
      "\n",
      "0 3\n",
      "False    54\n",
      "True     15\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.85      0.46        20\n",
      "           1       0.80      0.24      0.38        49\n",
      "\n",
      "   micro avg       0.42      0.42      0.42        69\n",
      "   macro avg       0.56      0.55      0.42        69\n",
      "weighted avg       0.66      0.42      0.40        69\n",
      "\n",
      "1 0\n",
      "False    60\n",
      "True      9\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.95      0.47        20\n",
      "           1       0.89      0.16      0.28        49\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        69\n",
      "   macro avg       0.60      0.56      0.38        69\n",
      "weighted avg       0.72      0.39      0.33        69\n",
      "\n",
      "1 1\n",
      "False    56\n",
      "True     13\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.85      0.45        20\n",
      "           1       0.77      0.20      0.32        49\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        69\n",
      "   macro avg       0.54      0.53      0.38        69\n",
      "weighted avg       0.63      0.39      0.36        69\n",
      "\n",
      "1 2\n",
      "False    61\n",
      "True      8\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.80      0.40        20\n",
      "           1       0.50      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.29      0.29      0.29        69\n",
      "   macro avg       0.38      0.44      0.27        69\n",
      "weighted avg       0.43      0.29      0.21        69\n",
      "\n",
      "1 3\n",
      "False    44\n",
      "True     25\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        20\n",
      "           1       0.68      0.35      0.46        49\n",
      "\n",
      "   micro avg       0.42      0.42      0.42        69\n",
      "   macro avg       0.48      0.47      0.42        69\n",
      "weighted avg       0.56      0.42      0.43        69\n",
      "\n",
      "2 0\n",
      "False    60\n",
      "True      9\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.95      0.47        20\n",
      "           1       0.89      0.16      0.28        49\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        69\n",
      "   macro avg       0.60      0.56      0.38        69\n",
      "weighted avg       0.72      0.39      0.33        69\n",
      "\n",
      "2 1\n",
      "False    58\n",
      "True     11\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.85      0.44        20\n",
      "           1       0.73      0.16      0.27        49\n",
      "\n",
      "   micro avg       0.36      0.36      0.36        69\n",
      "   macro avg       0.51      0.51      0.35        69\n",
      "weighted avg       0.60      0.36      0.32        69\n",
      "\n",
      "2 2\n",
      "False    61\n",
      "True      8\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.85      0.42        20\n",
      "           1       0.62      0.10      0.18        49\n",
      "\n",
      "   micro avg       0.32      0.32      0.32        69\n",
      "   macro avg       0.45      0.48      0.30        69\n",
      "weighted avg       0.52      0.32      0.25        69\n",
      "\n",
      "2 3\n",
      "False    57\n",
      "True     12\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.80      0.42        20\n",
      "           1       0.67      0.16      0.26        49\n",
      "\n",
      "   micro avg       0.35      0.35      0.35        69\n",
      "   macro avg       0.47      0.48      0.34        69\n",
      "weighted avg       0.55      0.35      0.31        69\n",
      "\n",
      "3 0\n",
      "False    66\n",
      "True      3\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.47        20\n",
      "           1       1.00      0.06      0.12        49\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        69\n",
      "   macro avg       0.65      0.53      0.29        69\n",
      "weighted avg       0.80      0.33      0.22        69\n",
      "\n",
      "3 1\n",
      "False    65\n",
      "True      4\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      1.00      0.47        20\n",
      "           1       1.00      0.08      0.15        49\n",
      "\n",
      "   micro avg       0.35      0.35      0.35        69\n",
      "   macro avg       0.65      0.54      0.31        69\n",
      "weighted avg       0.80      0.35      0.24        69\n",
      "\n",
      "3 2\n",
      "False    62\n",
      "True      7\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.85      0.41        20\n",
      "           1       0.57      0.08      0.14        49\n",
      "\n",
      "   micro avg       0.30      0.30      0.30        69\n",
      "   macro avg       0.42      0.47      0.28        69\n",
      "weighted avg       0.49      0.30      0.22        69\n",
      "\n",
      "3 3\n",
      "False    54\n",
      "True     15\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.80      0.43        20\n",
      "           1       0.73      0.22      0.34        49\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        69\n",
      "   macro avg       0.51      0.51      0.39        69\n",
      "weighted avg       0.61      0.39      0.37        69\n",
      "\n",
      "4 0\n",
      "False    56\n",
      "True     13\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.80      0.42        20\n",
      "           1       0.69      0.18      0.29        49\n",
      "\n",
      "   micro avg       0.36      0.36      0.36        69\n",
      "   macro avg       0.49      0.49      0.36        69\n",
      "weighted avg       0.57      0.36      0.33        69\n",
      "\n",
      "4 1\n",
      "False    55\n",
      "True     14\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.75      0.40        20\n",
      "           1       0.64      0.18      0.29        49\n",
      "\n",
      "   micro avg       0.35      0.35      0.35        69\n",
      "   macro avg       0.46      0.47      0.34        69\n",
      "weighted avg       0.54      0.35      0.32        69\n",
      "\n",
      "4 2\n",
      "False    59\n",
      "True     10\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.80      0.41        20\n",
      "           1       0.60      0.12      0.20        49\n",
      "\n",
      "   micro avg       0.32      0.32      0.32        69\n",
      "   macro avg       0.44      0.46      0.30        69\n",
      "weighted avg       0.50      0.32      0.26        69\n",
      "\n",
      "4 3\n",
      "False    62\n",
      "True      7\n",
      "dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.90      0.44        20\n",
      "           1       0.71      0.10      0.18        49\n",
      "\n",
      "   micro avg       0.33      0.33      0.33        69\n",
      "   macro avg       0.50      0.50      0.31        69\n",
      "weighted avg       0.59      0.33      0.25        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predictions_k(model, X, k):\n",
    "    probs = model.predict_proba(X)\n",
    "    return probs[:, 1] >= k\n",
    "\n",
    "# modelss = [[model]]\n",
    "for j, models in enumerate(modelss):\n",
    "    for i, model in enumerate(models):\n",
    "        print(j, i)\n",
    "        predictions = model.predict(test_df[X_colss[j]].values)\n",
    "        predictions = predictions_k(model, test_df[X_colss[j]].values, 0.6)\n",
    "        print(pd.Series(predictions).value_counts())\n",
    "        print(classification_report(test_df[Y_cols].values, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.41        20\n",
      "           1       0.85      0.92      0.88        49\n",
      "           2       0.91      0.80      0.85        65\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       134\n",
      "   macro avg       0.71      0.72      0.71       134\n",
      "weighted avg       0.81      0.79      0.80       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = test_df_human.is_answerable_human.apply(lambda x: label_map[x]).values\n",
    "labels = test_df_human.is_answerable.apply(lambda x: label_map[x]).values\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('classification_data/q_classification_model_final_suggestive.pkl', 'wb') as fp:\n",
    "#     pickle.dump(modelss[4][0], fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classification_data/q_classification_model_final_suggestive.pkl', 'rb') as fp:\n",
    "    model = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
