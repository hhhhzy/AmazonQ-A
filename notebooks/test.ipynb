{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nitish/Documents/Box Sync/cmu/acads/capstone/src\n"
     ]
    }
   ],
   "source": [
    "cd /Users/nitish/Documents/Box Sync/cmu/acads/capstone/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.5093 -0.3024\n",
      "-0.9533  0.2983\n",
      "-0.0038 -0.1917\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "Variable containing:\n",
      "-0.5820  0.1418  0.9501 -1.3768\n",
      "-0.9857 -0.0146 -1.9269 -2.7882\n",
      "-0.2955  0.2484  2.2448  1.2226\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = Variable(torch.randn((3,2)))\n",
    "b = Variable(torch.randn((3,4)))\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "c = torch.cat([a, b], 1)\n",
    "# torch.mean([a[:,1], b[:, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0995 -0.4050\n",
       "-0.8414 -0.5641\n",
       "-0.9850 -0.4675\n",
       "[torch.FloatTensor of size 3x2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "m(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Seqs:\n",
      " Variable containing:\n",
      " 3  4  5  9\n",
      " 2  1  9  0\n",
      " 7  3  0  0\n",
      "[torch.LongTensor of size 3x4]\n",
      "\n",
      "Input Lens:\n",
      " [4, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "h_size = 5\n",
    "vocab_size = 10\n",
    "n_layers = 1\n",
    "rnn_cell = nn.LSTM\n",
    "\n",
    "inputs = [[3, 4, 5, 9], [2, 1, 9, 0], [7, 3, 0, 0]]\n",
    "input_seqs = Variable(torch.Tensor(inputs).type(torch.LongTensor))\n",
    "input_lengths = [4, 3, 2]\n",
    "print('Input Seqs:\\n', input_seqs)\n",
    "print('Input Lens:\\n', input_lengths)\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, h_size)\n",
    "rnn = rnn_cell(h_size, h_size, n_layers, batch_first=True)\n",
    "out = nn.Linear(h_size, vocab_size)\n",
    "log_softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "run language_models/encoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.1783  0.1305  0.3269  0.1993 -0.1081\n",
       "  -0.1992  0.0355 -0.0036  0.0507 -0.0407\n",
       "  -0.0525 -0.2854 -0.1313 -0.0408  0.1352\n",
       " \n",
       " (1 ,.,.) = \n",
       "  -0.0733 -0.1941  0.2196  0.3833  0.3866\n",
       "  -0.0768 -0.1990  0.2210  0.3720  0.3562\n",
       "  -0.0902 -0.1927  0.1999  0.3047  0.3821\n",
       " [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.6393  0.2224  0.4575  0.3795 -0.1553\n",
       "  -0.3978  0.0607 -0.0090  0.1446 -0.0560\n",
       "  -0.1090 -0.6560 -0.4316 -0.1356  0.2062\n",
       " \n",
       " (1 ,.,.) = \n",
       "  -0.1529 -0.6098  0.4794  0.7464  0.7466\n",
       "  -0.1648 -0.6258  0.4770  0.7577  0.6996\n",
       "  -0.1825 -0.6340  0.4540  0.5759  0.7466\n",
       " [torch.FloatTensor of size 2x3x5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedded = embedding(input_seqs)\n",
    "# nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "\n",
    "en = Encoder(vocab_size, h_size, 10, 0, 2)\n",
    "e_output, e_h = en(input_seqs)\n",
    "e_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -2.1324 -2.6975 -2.5654 -2.1529 -2.9983 -2.2672 -2.7024 -2.1324 -1.9264\n",
       " -2.2120 -2.7272 -2.4569 -2.1479 -2.8743 -2.1848 -2.5828 -2.1335 -2.0950\n",
       " -2.1684 -2.7473 -2.5228 -2.1206 -2.9412 -2.2134 -2.7068 -2.1196 -2.0780\n",
       " -2.0968 -2.7021 -2.4804 -2.1183 -3.0872 -2.3109 -2.7187 -2.0316 -2.1619\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -1.9929\n",
       " -1.9901\n",
       " -1.9160\n",
       " -1.9028\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -2.2698 -2.7617 -2.4961 -2.1100 -2.7758 -2.1229 -2.6067 -2.1677 -2.1493\n",
       " -2.1127 -2.7987 -2.5321 -2.1670 -3.0314 -2.2366 -2.7914 -2.1341 -1.9629\n",
       " -2.0809 -2.7231 -2.4855 -2.1384 -3.1174 -2.3136 -2.7428 -2.0284 -2.1326\n",
       " -2.0740 -2.6650 -2.4917 -2.1053 -3.1199 -2.3514 -2.7283 -2.0298 -2.1341\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -1.9443\n",
       " -1.9040\n",
       " -1.8922\n",
       " -1.9262\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 8 \n",
       "  -2.1099 -2.6920 -2.5253 -2.0965 -3.0273 -2.2964 -2.7451 -2.1084 -2.0414\n",
       " -2.1040 -2.6710 -2.5422 -2.0998 -3.0422 -2.3121 -2.7374 -2.0980 -2.0260\n",
       " -2.0855 -2.6703 -2.5176 -2.1164 -3.0981 -2.3334 -2.7245 -2.0429 -2.0922\n",
       " -2.0778 -2.6643 -2.5033 -2.1182 -3.1150 -2.3453 -2.7182 -2.0322 -2.1067\n",
       "\n",
       "Columns 9 to 9 \n",
       "  -1.9415\n",
       " -1.9547\n",
       " -1.9335\n",
       " -1.9365\n",
       "[torch.FloatTensor of size 3x4x10]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = input_seqs\n",
    "max_len = 8\n",
    "\n",
    "batch_size, output_size = input.size()\n",
    "lengths = np.array([max_len] * batch_size)\n",
    "\n",
    "embedded = embedding(input)\n",
    "hidden = e_h\n",
    "\n",
    "output, hidden = rnn(embedded, hidden)\n",
    "softmax = log_softmax(out(output.contiguous().view(-1, h_size))).view(batch_size, output_size, -1)\n",
    "# embedded = embedding(input_seqs)\n",
    "\n",
    "# decoder_outputs = []\n",
    "# output_seqs = []\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0 \n",
    "eos_id = 3\n",
    "softmax_idx = softmax[:, 2, :]\n",
    "symbols = softmax_idx.topk(1)[1]\n",
    "is_eos = symbols.data.eq(eos_id)\n",
    "is_eos, is_eos.dim()\n",
    "is_eos.cpu().view(-1).numpy()\n",
    "\n",
    "eos_batches = is_eos.cpu().view(-1).numpy()\n",
    "update_idx = (idx < lengths) & (symbols.data.cpu().squeeze().numpy() == eos_id)\n",
    "#lengths[update_idx] = len(sequence_symbols)\n",
    "# lengths[update_idx] = idx\n",
    "update_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 9\n",
       " 9\n",
       " 9\n",
       "[torch.LongTensor of size 3x1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = input_seqs[:, 2].unsqueeze(1)\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3\n",
       " 2\n",
       " 7\n",
       "[torch.LongTensor of size 3x1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs[:, 0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run src/language_models/decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = Encoder(vocab_size, h_size, 10)\n",
    "de = Decoder(vocab_size, h_size, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  5  0  0\n",
       "  1  1  1\n",
       "  1  5  0\n",
       " [torch.LongTensor of size 3x3], array([ 10.,   1.,   1.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_output, e_h = en(input_seqs, input_lengths)\n",
    "\n",
    "de(input_seqs, e_h, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  4  5  9\n",
       " 2  1  9  0\n",
       " 7  3  0  0\n",
       "[torch.LongTensor of size 3x4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = [(1,), (2,), (3,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,), (2,), (3,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  4  5  9\n",
       " 2  1  9  0\n",
       " 7  3  0  0\n",
       "[torch.LongTensor of size 3x4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.1783  0.1305  0.3269  0.1993 -0.1081\n",
       "  -0.1992  0.0355 -0.0036  0.0507 -0.0407\n",
       "  -0.0525 -0.2854 -0.1313 -0.0408  0.1352\n",
       " \n",
       " (1 ,.,.) = \n",
       "  -0.0733 -0.1941  0.2196  0.3833  0.3866\n",
       "  -0.0768 -0.1990  0.2210  0.3720  0.3562\n",
       "  -0.0902 -0.1927  0.1999  0.3047  0.3821\n",
       " [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       " (0 ,.,.) = \n",
       "  -0.6393  0.2224  0.4575  0.3795 -0.1553\n",
       "  -0.3978  0.0607 -0.0090  0.1446 -0.0560\n",
       "  -0.1090 -0.6560 -0.4316 -0.1356  0.2062\n",
       " \n",
       " (1 ,.,.) = \n",
       "  -0.1529 -0.6098  0.4794  0.7464  0.7466\n",
       "  -0.1648 -0.6258  0.4770  0.7577  0.6996\n",
       "  -0.1825 -0.6340  0.4540  0.5759  0.7466\n",
       " [torch.FloatTensor of size 2x3x5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Variable containing:\n",
       "  (0 ,.,.) = \n",
       "   -0.1783  0.1305  0.3269  0.1993 -0.1081\n",
       "   -0.1992  0.0355 -0.0036  0.0507 -0.0407\n",
       "   -0.0525 -0.2854 -0.1313 -0.0408  0.1352\n",
       "  \n",
       "  (1 ,.,.) = \n",
       "   -0.0733 -0.1941  0.2196  0.3833  0.3866\n",
       "   -0.0768 -0.1990  0.2210  0.3720  0.3562\n",
       "   -0.0902 -0.1927  0.1999  0.3047  0.3821\n",
       "  [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       "  (0 ,.,.) = \n",
       "   -0.6393  0.2224  0.4575  0.3795 -0.1553\n",
       "   -0.3978  0.0607 -0.0090  0.1446 -0.0560\n",
       "   -0.1090 -0.6560 -0.4316 -0.1356  0.2062\n",
       "  \n",
       "  (1 ,.,.) = \n",
       "   -0.1529 -0.6098  0.4794  0.7464  0.7466\n",
       "   -0.1648 -0.6258  0.4770  0.7577  0.6996\n",
       "   -0.1825 -0.6340  0.4540  0.5759  0.7466\n",
       "  [torch.FloatTensor of size 2x3x5]), (Variable containing:\n",
       "  (0 ,.,.) = \n",
       "   -0.1783  0.1305  0.3269  0.1993 -0.1081\n",
       "   -0.1992  0.0355 -0.0036  0.0507 -0.0407\n",
       "   -0.0525 -0.2854 -0.1313 -0.0408  0.1352\n",
       "  \n",
       "  (1 ,.,.) = \n",
       "   -0.0733 -0.1941  0.2196  0.3833  0.3866\n",
       "   -0.0768 -0.1990  0.2210  0.3720  0.3562\n",
       "   -0.0902 -0.1927  0.1999  0.3047  0.3821\n",
       "  [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       "  (0 ,.,.) = \n",
       "   -0.6393  0.2224  0.4575  0.3795 -0.1553\n",
       "   -0.3978  0.0607 -0.0090  0.1446 -0.0560\n",
       "   -0.1090 -0.6560 -0.4316 -0.1356  0.2062\n",
       "  \n",
       "  (1 ,.,.) = \n",
       "   -0.1529 -0.6098  0.4794  0.7464  0.7466\n",
       "   -0.1648 -0.6258  0.4770  0.7577  0.6996\n",
       "   -0.1825 -0.6340  0.4540  0.5759  0.7466\n",
       "  [torch.FloatTensor of size 2x3x5]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_h, e_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -0.1783  0.1305  0.3269  0.1993 -0.1081\n",
       " -0.1992  0.0355 -0.0036  0.0507 -0.0407\n",
       " -0.0525 -0.2854 -0.1313 -0.0408  0.1352\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.0733 -0.1941  0.2196  0.3833  0.3866\n",
       " -0.0768 -0.1990  0.2210  0.3720  0.3562\n",
       " -0.0902 -0.1927  0.1999  0.3047  0.3821\n",
       "[torch.FloatTensor of size 2x3x5]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.cat([i.unsqueeze(0) for i in list(zip(*[e_h, e_h2]))[0]], 0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.8217  1.1305  1.3269  1.1993  0.8919\n",
       "   0.8008  1.0355  0.9964  1.0507  0.9593\n",
       "   0.9475  0.7146  0.8687  0.9592  1.1352\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.9267  0.8059  1.2196  1.3833  1.3866\n",
       "   0.9232  0.8010  1.2210  1.3720  1.3562\n",
       "   0.9098  0.8073  1.1999  1.3047  1.3821\n",
       " [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.3607  1.2224  1.4575  1.3795  0.8447\n",
       "   0.6022  1.0607  0.9910  1.1446  0.9440\n",
       "   0.8910  0.3440  0.5684  0.8644  1.2062\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.8471  0.3902  1.4794  1.7464  1.7466\n",
       "   0.8352  0.3742  1.4770  1.7577  1.6996\n",
       "   0.8175  0.3660  1.4540  1.5759  1.7466\n",
       " [torch.FloatTensor of size 2x3x5]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _mean(vars):\n",
    "    return torch.mean(torch.cat([i.unsqueeze(0) for i in vars], 0), 0)\n",
    "\n",
    "reviews_hidden = [e_h, tuple([i + 1 for i in e_h]), tuple([i + 2 for i in e_h])]\n",
    "d_hidden = list(map(_mean, list(zip(*reviews_hidden))))\n",
    "d_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.8217  1.1305  1.3269  1.1993  0.8919\n",
       "   0.8008  1.0355  0.9964  1.0507  0.9593\n",
       "   0.9475  0.7146  0.8687  0.9592  1.1352\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.9267  0.8059  1.2196  1.3833  1.3866\n",
       "   0.9232  0.8010  1.2210  1.3720  1.3562\n",
       "   0.9098  0.8073  1.1999  1.3047  1.3821\n",
       " [torch.FloatTensor of size 2x3x5], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.3607  1.2224  1.4575  1.3795  0.8447\n",
       "   0.6022  1.0607  0.9910  1.1446  0.9440\n",
       "   0.8910  0.3440  0.5684  0.8644  1.2062\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.8471  0.3902  1.4794  1.7464  1.7466\n",
       "   0.8352  0.3742  1.4770  1.7577  1.6996\n",
       "   0.8175  0.3660  1.4540  1.5759  1.7466\n",
       " [torch.FloatTensor of size 2x3x5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_hidden[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  4  5  9\n",
       " 2  1  9  0\n",
       " 7  3  0  0\n",
       "[torch.LongTensor of size 3x4]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "masked_select(): argument 'mask' (position 1) must be Variable, not torch.ByteTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-d0edfcc0ca06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# a = np.array(input_lengths) >= 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a = torch.ByteTensor(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: masked_select(): argument 'mask' (position 1) must be Variable, not torch.ByteTensor"
     ]
    }
   ],
   "source": [
    "# input_seqs[, 1:2]\n",
    "# a = np.array(input_lengths) >= 3\n",
    "# a = torch.ByteTensor(a)\n",
    "torch.masked_select(input_seqs, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4  5\n",
       " 1  9\n",
       " 3  0\n",
       "[torch.LongTensor of size 3x2]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = torch.LongTensor(input_lengths).ge(3)\n",
    "torch.index_select(input_seqs, 1, Variable(torch.LongTensor([1,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "from trainer import Trainer, hsizes\n",
    "from dataloader import AmazonDataLoader\n",
    "from dataset import AmazonDataset\n",
    "from models.model import LM\n",
    "from logger import Logger\n",
    "from vocabulary import Vocabulary\n",
    "import constants as C\n",
    "\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name, mode = C.LM_QUESTION_ANSWERS, 'train'\n",
    "save_dir = 'models/saved_models/Video_Games/LM_A/2018-04-02-07-38-46'\n",
    "logger = Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path, output_file = save_dir, 'output.txt'\n",
    "params_filename = '%s/%s' % (input_path, C.SAVED_PARAMS_FILENAME)\n",
    "vocab_filename = '%s/%s' % (input_path, C.SAVED_VOCAB_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/saved_models/Video_Games/LM_A/2018-04-02-07-38-46/vocab.pkl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = json.load(open(params_filename, 'r'))\n",
    "vocab = pickle.load(open(vocab_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[C.MAX_QUESTION_LEN] = 100\n",
    "params[C.MAX_ANSWER_LEN] = 100\n",
    "params[C.MAX_REVIEW_LEN] = 100\n",
    "params[C.REVIEW_SELECT_NUM] = 5\n",
    "params[C.REVIEW_SELECT_MODE] = 'WILSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset for [VIDEO_GAMES]..\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9b8ba1866e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCATEGORY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/Documents/Box Sync/cmu/acads/capstone/src/main.py\u001b[0m in \u001b[0;36m_get_dataset\u001b[0;34m(model, category, params, logger)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazonDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving dataset in file: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Box Sync/cmu/acads/capstone/src/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/train-%s.pickle'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINPUT_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Box Sync/cmu/acads/capstone/src/dataset.py\u001b[0m in \u001b[0;36mcreate_vocab\u001b[0;34m(self, train_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mquestionsList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUESTIONS_LIST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestionsList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_question_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "model_name = params[C.MODEL_NAME]\n",
    "dataset = _get_dataset(\n",
    "    model_name,\n",
    "    params[C.CATEGORY],\n",
    "    params,\n",
    "    logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AmazonDataLoader(\n",
    "    dataset.val if mode == C.DEV_TYPE else dataset.test,\n",
    "    model_name,\n",
    "    params[C.BATCH_SIZE]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['hdim_r'] = params['hdim']\n",
    "params['hdim_q'] = params['hdim']\n",
    "params['hdim_a'] = params['hdim']\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(\n",
    "    vocab.get_vocab_size(),\n",
    "    hsizes(params, model_name),\n",
    "    params[C.EMBEDDING_DIM],\n",
    "    params[C.OUTPUT_MAX_LEN],\n",
    "    params[C.H_LAYERS],\n",
    "    params[C.DROPOUT],\n",
    "    params[C.MODEL_NAME]\n",
    ")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "map_location = None if use_cuda else lambda storage, loc: storage # assuming the model was saved from a gpu machine\n",
    "model_filename = '%s/%s_%d' % (input_path, C.SAVED_MODEL_FILENAME, epoch)\n",
    "model.load_state_dict(torch.load(model_filename, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL : None\n",
      "PARAMS: {'batch_size': 20, 'category': 'Video_Games', 'decay_start_epoch': 10, 'dropout': 0.2, 'embedding_dim': 10, 'epochs': 25, 'global_norm_max': 5, 'h_layers': 2, 'hdim': 10, 'logfile': 'test.log', 'lr': 0.1, 'lr_decay': 0.5, 'model_name': 'LM_A', 'output_max_len': 128, 'teacher_forcing_ratio': 0.9, 'vocab_size': 20000, 'hdim_r': 10, 'hdim_q': 10, 'hdim_a': 10, 'epoch': 1}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "None,\n",
    "params,\n",
    "dev_loader=loader,\n",
    "#test_loader=loader,\n",
    "random_seed=RANDOM_SEED,\n",
    "vocab=vocab,\n",
    "logger=logger,\n",
    "save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "inputs = list(loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "run language_models/trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_seqs, quesion_seqs, review_seqs, answer_lengths = _extract_input_attributes(inputs, trainer.model_name)\n",
    "\n",
    "target_seqs, answer_seqs  = _var(answer_seqs), _var(answer_seqs)\n",
    "quesion_seqs = None if trainer.model_name == C.LM_ANSWERS else _var(quesion_seqs)\n",
    "review_seqs = map(_var, review_seqs) if trainer.model_name == C.LM_QUESTION_ANSWERS_REVIEWS else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       "       ...          ⋱          ...       \n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       " 6144  4840  6144  ...   4840  6144  6144\n",
       "[torch.LongTensor of size 20x128]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, output_seq, output_lengths = model(\n",
    "    quesion_seqs,\n",
    "    review_seqs,\n",
    "    answer_seqs,\n",
    "    target_seqs,\n",
    "    False\n",
    ")\n",
    "output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden = None\n",
    "batch_size = target_seqs.size(0)\n",
    "hidden = None\n",
    "output_seq_lengths = np.ones(batch_size) * model.decoder.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = target_seqs[:, 0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden = model.decoder.softmax_from_input(input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, softmax_idx = 0, output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = softmax_idx.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = torch.rand(x.shape)\n",
    "eps = 1e-20\n",
    "a = torch.log(-torch.log(U + eps) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  3939\n",
       " 12220\n",
       " 17367\n",
       " 14405\n",
       "  2675\n",
       " 19510\n",
       "  6860\n",
       " 17183\n",
       "  1260\n",
       "  5714\n",
       " 13826\n",
       "  6064\n",
       " 13061\n",
       " 13900\n",
       " 19559\n",
       " 14145\n",
       " 19786\n",
       " 12461\n",
       "  7921\n",
       "  9087\n",
       "[torch.LongTensor of size 20x1]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.topk(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7373"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(x.shape[1]), p=np.exp(x[1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitish/miniconda2/envs/capstone/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan, ...,  nan,  nan,  nan], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(x[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       "           ...               ⋱              ...            \n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       " -9.8561  -9.9789  -9.6853  ...  -10.2231  -9.8840 -10.0270\n",
       "[torch.FloatTensor of size 20x20004]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [1, 4, 2, 3]\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x)\n",
    "    return e / e.sum()\n",
    "\n",
    "samples = []\n",
    "temp = 0.1\n",
    "for _ in range(10000):\n",
    "    U = np.random.uniform(0, 1, (4))\n",
    "    ps = softmax(p)\n",
    "    eps = 1e-20\n",
    "    a = ps + np.log(-np.log(U + eps) + eps)\n",
    "#     a = p + np.log(-np.log(U + eps) + eps)\n",
    "    probs = softmax(a / temp)\n",
    "    sample = np.random.choice(range(len(p)), p=probs)\n",
    "#     samples.append(sample)\n",
    "    samples.append(np.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1685,  0.4004,  0.1929,  0.2382])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(samples) / len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(len(p)), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 18179    718   1659   5023  14401\n",
       "  9703  14756   3875  16307  13101\n",
       " 10733  18693   2417  14068  15517\n",
       " 14137   1445  15189   3273   1132\n",
       "  3461  14435   5531  11503   5242\n",
       " 18905  15542   5605  17338  14390\n",
       "  3494  19515   8723   8099  15361\n",
       " 14585  19907   5772   2367  13360\n",
       " 11702   1775   6492   5362   8827\n",
       "  6407     33  16740   6273  13579\n",
       "  9272    270  10162   3734  18743\n",
       " 17998  12587  16907   3478   4025\n",
       "  4773   8752   6144  14638  17080\n",
       "  5815   3234   1462  10263  19292\n",
       " 14306  11367  17205  17564  10795\n",
       " 10390  12132   4838  13735  15882\n",
       " 10716   8114  15125   3278    897\n",
       " 17117   9503   3933   7934  17051\n",
       " 16601  12803   4210  17446  10249\n",
       "  5926  12132  17539  17905   2566\n",
       "[torch.LongTensor of size 20x5]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial((softmax_idx / 0.1).exp(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 14335\n",
       " 14779\n",
       " 19078\n",
       "  2316\n",
       " 12586\n",
       " 11119\n",
       " 13797\n",
       "    51\n",
       "  7845\n",
       "  3133\n",
       "  7024\n",
       "  3921\n",
       "  1880\n",
       " 17710\n",
       " 19598\n",
       "  4910\n",
       " 11610\n",
       "  7629\n",
       " 12138\n",
       " 19373\n",
       "[torch.LongTensor of size 20x1]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_idx.exp().multinomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-42 *\n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       "          ...             ⋱             ...          \n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       " 0.1569  0.0462  0.8646  ...   0.0042  0.1191  0.0280\n",
       "[torch.FloatTensor of size 20x20004]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(softmax_idx / 0.1).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating dataset for [VIDEO_GAMES]..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:00, 356.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset from ../data/input/train-Video_Games.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [00:00, 591.46it/s]\n",
      "69it [00:00, 683.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the data = 12691\n",
      "Creating Dataset from ../data/input/val-Video_Games.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [00:00, 589.12it/s]\n",
      "63it [00:00, 626.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the data = 4310\n",
      "Creating Dataset from ../data/input/test-Video_Games.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [00:00, 588.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the data = 3995\n",
      "Saving dataset in file: saved_models/Video_Games/LM_A_Video_Games_1_20000.pkl\n",
      "Finished loading dataset for [VIDEO_GAMES] category and [LM_A] model..\n",
      "\n",
      " Model: LM_A, Mode = train, Category = Video_Games \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = utils.get_main_params()\n",
    "model_name, mode = args.model_name, args.mode\n",
    "save_dir = args.save_dir\n",
    "logger = Logger()\n",
    "resume, epoch = args.resume, args.epoch\n",
    "\n",
    "params = utils.get_model_params(model_name)\n",
    "params[C.MODEL_NAME] = model_name\n",
    "params[C.LOG_FILENAME] = logger.logfilename\n",
    "category = params[C.CATEGORY]\n",
    "params[C.BATCH_SIZE] = 64\n",
    "\n",
    "dataset = _get_dataset(model_name, category, params, logger)\n",
    "logger.log('\\n Model: %s, Mode = %s, Category = %s \\n' % (model_name, mode, category))\n",
    "train_loader = AmazonDataLoader(dataset.train, model_name, params[C.BATCH_SIZE])\n",
    "dev_loader = AmazonDataLoader(dataset.val, model_name, params[C.BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL : LM(\n",
      "  (decoder): Decoder(\n",
      "    (dropout): Dropout(p=0.2)\n",
      "    (embedding): Embedding(20004, 512)\n",
      "    (rnn): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (out): Linear(in_features=512, out_features=20004)\n",
      "    (log_softmax): LogSoftmax()\n",
      "  )\n",
      ")\n",
      "PARAMS: {'model_name': 'LM_A', 'category': 'Video_Games', 'review_select_mode': None, 'review_select_num': None, 'epochs': 25, 'batch_size': 64, 'dropout': 0.2, 'lr': 0.01, 'hdim_a': 512, 'hdim_r': None, 'hdim_q': None, 'embedding_dim': 512, 'h_layers': 2, 'lr_decay': 0.5, 'global_norm_max': 5, 'vocab_size': 20000, 'teacher_forcing_ratio': 0.9, 'output_max_len': 128, 'logfile': 'log_files/2018-04-18-14-59-28.log', 'max_question_len': 100, 'max_answer_len': 100, 'max_review_len': 200, 'resume_lr': None, 'save_dir': None}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    train_loader,\n",
    "    params,\n",
    "    dev_loader=dev_loader,\n",
    "    #test_loader=test_loader,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    vocab=dataset.vocab,\n",
    "    logger=logger,\n",
    "    resume_training=resume,\n",
    "    resume_epoch=epoch if resume else None,\n",
    "    save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = list(trainer.dataloader)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_seqs, quesion_seqs, review_seqs, answer_lengths = _extract_input_attributes(inputs, trainer.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seqs, answer_seqs  = _var(answer_seqs), _var(answer_seqs)\n",
    "quesion_seqs = None if trainer.model_name == C.LM_ANSWERS else _var(quesion_seqs)\n",
    "review_seqs = map(_var, review_seqs) if trainer.model_name == C.LM_QUESTION_ANSWERS_REVIEWS else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "     2     53     12  ...     750      4      1\n",
       "     2    109      5  ...    1558      4      1\n",
       "     2      5    169  ...    1161      4      1\n",
       "        ...            ⋱           ...         \n",
       "     2      8     26  ...       4      1      0\n",
       "     2     82    147  ...       4      1      0\n",
       "     2     55     40  ...       4      1      0\n",
       "[torch.LongTensor of size 64x55]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 17975   5765  18303  ...    4444  10599  14828\n",
       "  9885  10693  11597  ...    4411    162  18924\n",
       " 16396   6191  19331  ...   12610  15812  15881\n",
       "        ...            ⋱           ...         \n",
       "  5204  15883  15370  ...   19257   6293  18519\n",
       "  1024  16104  18868  ...    2464    355  13112\n",
       " 10323   6601   7275  ...   14665  10377  18335\n",
       "[torch.LongTensor of size 64x54]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs, output_seq, output_lengths = trainer.model(\n",
    "    quesion_seqs,\n",
    "    review_seqs,\n",
    "    answer_seqs,\n",
    "    target_seqs,\n",
    "    True\n",
    ")\n",
    "output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3470"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_seqs.cpu().data.numpy() != C.PAD_INDEX).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.EOS_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seqs.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 633.4193\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.criterion(outputs[1], target_seqs[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nitish/miniconda2/envs/capstone/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: All-NaN axis encountered\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmin([np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.9</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b\n",
       "0  5.0  6.0\n",
       "1  8.9  9.0\n",
       "2  0.0  3.0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = [5, 8.9, 0]\n",
    "b = [6, 9.0, 3]\n",
    "pd.DataFrame({'a': a, 'b': b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
